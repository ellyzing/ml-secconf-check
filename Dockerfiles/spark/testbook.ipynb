{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, StringIndexerModel\n",
    "from pyspark.ml.pipeline import PipelineModel\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Transformer\n",
    "\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/coalyonysh/Library/Python/3.9/lib/python/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "24/05/13 18:22:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/13 18:22:43 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"PySparkTitanikJob\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.105:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkTitanikJob</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x177a55370>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ActiveRun: >"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.start_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split, col\n",
    "df = spark.read.parquet('../part.0.parquet')\n",
    "tag_index = StringIndexer(inputCol='image_tag', outputCol=\"image_tag_index\", handleInvalid=\"skip\")\n",
    "user_index = StringIndexer(inputCol='user', outputCol=\"user_index\", handleInvalid=\"skip\")\n",
    "image_index = StringIndexer(inputCol='image', outputCol=\"image_index\", handleInvalid=\"skip\")\n",
    "\n",
    "df = tag_index.fit(df).transform(df)\n",
    "df = user_index.fit(df).transform(df)\n",
    "df = image_index.fit(df).transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------------------+----------------+-----------+-----------------+-------------+---------+--------------------+---------------------------+------------------------+---------+------+---------------+----------+-----------+\n",
      "|has_install_or_update|has_clean_commands|has_exposed_port|port_number|has_setuid_setgid|    image_tag|     user|               image|has_package_update_commands|dangerous_commands_count|safe_copy|result|image_tag_index|user_index|image_index|\n",
      "+---------------------+------------------+----------------+-----------+-----------------+-------------+---------+--------------------+---------------------------+------------------------+---------+------+---------------+----------+-----------+\n",
      "|                 true|             false|           false|          0|            false|       latest|     root|              alpine|                      false|                       2|    false|     1|            0.0|       0.0|        1.0|\n",
      "|                false|              true|           false|          0|            false|       latest|     root|              alpine|                      false|                       0|     true|     0|            0.0|       0.0|        1.0|\n",
      "|                false|              true|            true|       9104|            false|          1.6|     root|             haproxy|                      false|                       0|     true|     0|           81.0|       0.0|       37.0|\n",
      "|                false|              true|           false|          0|            false|          1.7|     root|              golang|                      false|                       0|     true|     0|           58.0|       0.0|        7.0|\n",
      "|                 true|             false|            true|       9010|            false|          3.1|     root|   gliderlabs/alpine|                      false|                       0|     true|     0|           52.0|       0.0|       17.0|\n",
      "|                false|              true|           false|          0|            false|alpine-3-php7|     root| webdevops/php-nginx|                      false|                       0|    false|     0|         2840.0|       0.0|      281.0|\n",
      "|                false|              true|           false|          0|            false|       latest|     root|     prom/prometheus|                      false|                       0|    false|     0|            0.0|       0.0|      179.0|\n",
      "|                 true|             false|           false|          0|            false|       latest|     root|              ubuntu|                       true|                       2|    false|     0|            0.0|       0.0|        0.0|\n",
      "|                 true|             false|           false|          0|            false|       latest|     root|   gliderlabs/alpine|                      false|                       1|     true|     1|            0.0|       0.0|       17.0|\n",
      "|                false|              true|           false|          0|            false|       latest|     root|              alpine|                      false|                       0|     true|     0|            0.0|       0.0|        1.0|\n",
      "|                false|              true|            true|         80|            false|       0.9.15|     root|phusion/passenger...|                       true|                       0|     true|     0|           77.0|       0.0|      186.0|\n",
      "|                 true|             false|           false|          0|            false|       latest|     root|              ubuntu|                       true|                       1|    false|     0|            0.0|       0.0|        0.0|\n",
      "|                 true|             false|           false|          0|            false|        14.04|     root|              ubuntu|                       true|                       0|    false|     0|            1.0|       0.0|        0.0|\n",
      "|                 true|             false|           false|          0|            false|        14.04|     root|              ubuntu|                       true|                       1|     true|     0|            1.0|       0.0|        0.0|\n",
      "|                 true|             false|            true|       5232|            false|       latest|     root|              alpine|                      false|                       1|    false|     1|            0.0|       0.0|        1.0|\n",
      "|                 true|             false|           false|          0|            false|        16.04|audiogram|              ubuntu|                       true|                       1|    false|     0|            2.0|     445.0|        0.0|\n",
      "|                 true|             false|           false|          0|            false|       latest|     root|                ruby|                       true|                       0|     true|     0|            0.0|       0.0|        6.0|\n",
      "|                 true|             false|           false|          0|            false|       latest|     root|                ruby|                       true|                       0|    false|     0|            0.0|       0.0|        6.0|\n",
      "|                 true|             false|           false|          0|            false| 8-jre-alpine|     root|             openjdk|                      false|                       0|    false|     0|           33.0|       0.0|       11.0|\n",
      "|                 true|              true|           false|          0|            false|        8-jre|     root|             openjdk|                       true|                       0|    false|     0|           25.0|       0.0|       11.0|\n",
      "+---------------------+------------------+----------------+-----------+-----------------+-------------+---------+--------------------+---------------------------+------------------------+---------+------+---------------+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/13 19:39:31 WARN DAGScheduler: Broadcasting large task binary with size 1077.9 KiB\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------------------+----------------+-----------+-----------------+-------------+---------+--------------------+---------------------------+------------------------+---------+------+---------------+----------+-----------+--------------------+\n",
      "|has_install_or_update|has_clean_commands|has_exposed_port|port_number|has_setuid_setgid|    image_tag|     user|               image|has_package_update_commands|dangerous_commands_count|safe_copy|result|image_tag_index|user_index|image_index|            features|\n",
      "+---------------------+------------------+----------------+-----------+-----------------+-------------+---------+--------------------+---------------------------+------------------------+---------+------+---------------+----------+-----------+--------------------+\n",
      "|                 true|             false|           false|          0|            false|       latest|     root|              alpine|                      false|                       2|    false|     1|            0.0|       0.0|        1.0|(11,[0,7,9],[1.0,...|\n",
      "|                false|              true|           false|          0|            false|       latest|     root|              alpine|                      false|                       0|     true|     0|            0.0|       0.0|        1.0|(11,[1,7,10],[1.0...|\n",
      "|                false|              true|            true|       9104|            false|          1.6|     root|             haproxy|                      false|                       0|     true|     0|           81.0|       0.0|       37.0|(11,[1,2,3,5,7,10...|\n",
      "|                false|              true|           false|          0|            false|          1.7|     root|              golang|                      false|                       0|     true|     0|           58.0|       0.0|        7.0|(11,[1,5,7,10],[1...|\n",
      "|                 true|             false|            true|       9010|            false|          3.1|     root|   gliderlabs/alpine|                      false|                       0|     true|     0|           52.0|       0.0|       17.0|(11,[0,2,3,5,7,10...|\n",
      "|                false|              true|           false|          0|            false|alpine-3-php7|     root| webdevops/php-nginx|                      false|                       0|    false|     0|         2840.0|       0.0|      281.0|(11,[1,5,7],[1.0,...|\n",
      "|                false|              true|           false|          0|            false|       latest|     root|     prom/prometheus|                      false|                       0|    false|     0|            0.0|       0.0|      179.0|(11,[1,7],[1.0,17...|\n",
      "|                 true|             false|           false|          0|            false|       latest|     root|              ubuntu|                       true|                       2|    false|     0|            0.0|       0.0|        0.0|(11,[0,8,9],[1.0,...|\n",
      "|                 true|             false|           false|          0|            false|       latest|     root|   gliderlabs/alpine|                      false|                       1|     true|     1|            0.0|       0.0|       17.0|(11,[0,7,9,10],[1...|\n",
      "|                false|              true|           false|          0|            false|       latest|     root|              alpine|                      false|                       0|     true|     0|            0.0|       0.0|        1.0|(11,[1,7,10],[1.0...|\n",
      "|                false|              true|            true|         80|            false|       0.9.15|     root|phusion/passenger...|                       true|                       0|     true|     0|           77.0|       0.0|      186.0|[0.0,1.0,1.0,80.0...|\n",
      "|                 true|             false|           false|          0|            false|       latest|     root|              ubuntu|                       true|                       1|    false|     0|            0.0|       0.0|        0.0|(11,[0,8,9],[1.0,...|\n",
      "|                 true|             false|           false|          0|            false|        14.04|     root|              ubuntu|                       true|                       0|    false|     0|            1.0|       0.0|        0.0|(11,[0,5,8],[1.0,...|\n",
      "|                 true|             false|           false|          0|            false|        14.04|     root|              ubuntu|                       true|                       1|     true|     0|            1.0|       0.0|        0.0|(11,[0,5,8,9,10],...|\n",
      "|                 true|             false|            true|       5232|            false|       latest|     root|              alpine|                      false|                       1|    false|     1|            0.0|       0.0|        1.0|(11,[0,2,3,7,9],[...|\n",
      "|                 true|             false|           false|          0|            false|        16.04|audiogram|              ubuntu|                       true|                       1|    false|     0|            2.0|     445.0|        0.0|(11,[0,5,6,8,9],[...|\n",
      "|                 true|             false|           false|          0|            false|       latest|     root|                ruby|                       true|                       0|     true|     0|            0.0|       0.0|        6.0|(11,[0,7,8,10],[1...|\n",
      "|                 true|             false|           false|          0|            false|       latest|     root|                ruby|                       true|                       0|    false|     0|            0.0|       0.0|        6.0|(11,[0,7,8],[1.0,...|\n",
      "|                 true|             false|           false|          0|            false| 8-jre-alpine|     root|             openjdk|                      false|                       0|    false|     0|           33.0|       0.0|       11.0|(11,[0,5,7],[1.0,...|\n",
      "|                 true|              true|           false|          0|            false|        8-jre|     root|             openjdk|                       true|                       0|    false|     0|           25.0|       0.0|       11.0|(11,[0,1,5,7,8],[...|\n",
      "+---------------------+------------------+----------------+-----------+-----------------+-------------+---------+--------------------+---------------------------+------------------------+---------+------+---------------+----------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/13 19:40:46 WARN DAGScheduler: Broadcasting large task binary with size 1091.6 KiB\n"
     ]
    }
   ],
   "source": [
    "feature = VectorAssembler(\n",
    "    inputCols=[\"has_install_or_update\", \n",
    "                             \"has_clean_commands\", \n",
    "                             \"has_exposed_port\", \n",
    "                             \"port_number\", \n",
    "                             \"has_setuid_setgid\", \n",
    "                             \"image_tag_index\", \n",
    "                             \"user_index\",\n",
    "                             \"image_index\",\n",
    "                             \"has_package_update_commands\",\n",
    "                             \"dangerous_commands_count\",\n",
    "                             \"safe_copy\"],\n",
    "    outputCol=\"features\")\n",
    "feature_vector= feature.transform(df)\n",
    "feature_vector.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/13 19:40:50 WARN DAGScheduler: Broadcasting large task binary with size 1113.8 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------------------+----------------+-----------+-----------------+--------------------+---------+--------------------+---------------------------+------------------------+---------+------+---------------+----------+-----------+--------------------+\n",
      "|has_install_or_update|has_clean_commands|has_exposed_port|port_number|has_setuid_setgid|           image_tag|     user|               image|has_package_update_commands|dangerous_commands_count|safe_copy|result|image_tag_index|user_index|image_index|            features|\n",
      "+---------------------+------------------+----------------+-----------+-----------------+--------------------+---------+--------------------+---------------------------+------------------------+---------+------+---------------+----------+-----------+--------------------+\n",
      "|                false|              true|           false|          0|            false|            \"${tag}\"|     root|   cognexa/archlinux|                      false|                       0|    false|     0|         1660.0|       0.0|     6741.0|(11,[1,5,7],[1.0,...|\n",
      "|                false|              true|           false|          0|            false|            \"${tag}\"|     root|      cognexa/cxflow|                      false|                       0|    false|     0|         1660.0|       0.0|     6742.0|(11,[1,5,7],[1.0,...|\n",
      "|                false|              true|           false|          0|            false|            $CMS_TAG|     root|misli/django-cms-...|                      false|                       0|    false|     0|         1661.0|       0.0|     2354.0|(11,[1,5,7],[1.0,...|\n",
      "|                false|              true|           false|          0|            false|            $CMS_TAG|     root|misli/django-cms-...|                      false|                       0|    false|     0|         1661.0|       0.0|     2354.0|(11,[1,5,7],[1.0,...|\n",
      "|                false|              true|           false|          0|            false|            $CMS_TAG|     root|misli/django-cms-...|                      false|                       0|    false|     0|         1661.0|       0.0|     2354.0|(11,[1,5,7],[1.0,...|\n",
      "|                false|              true|           false|          0|            false|           $DCKR_TAG|$username|    bvberkum/treebox|                      false|                       1|     true|     1|         3130.0|      49.0|     6276.0|(11,[1,5,6,7,9,10...|\n",
      "|                false|              true|           false|          0|            false|     $JUPYTERHUB_VER|     root|jupyterhub/jupyte...|                      false|                       1|    false|     0|         3137.0|       0.0|      305.0|(11,[1,5,7,9],[1....|\n",
      "|                false|              true|           false|          0|            false|$LOCALSTACK_DOCKE...|     root|localstack/locals...|                      false|                       0|    false|     0|         3138.0|       0.0|     1584.0|(11,[1,5,7],[1.0,...|\n",
      "|                false|              true|           false|          0|            false|       $NODE_VERSION|     root|                node|                      false|                       0|    false|     0|         1408.0|       0.0|        2.0|(11,[1,5,7],[1.0,...|\n",
      "|                false|              true|           false|          0|            false|       $SOLR_VERSION|     solr|                solr|                      false|                       0|     true|     0|         3144.0|      76.0|      143.0|(11,[1,5,6,7,10],...|\n",
      "|                false|              true|           false|          0|            false|            $VERSION|     root|              ubuntu|                       true|                       0|    false|     0|         1094.0|       0.0|        0.0|(11,[1,5,8],[1.0,...|\n",
      "|                false|              true|           false|          0|            false|            $version|     root|     quanted/qed_py3|                      false|                       0|    false|     0|         1409.0|       0.0|     1669.0|(11,[1,5,7],[1.0,...|\n",
      "|                false|              true|           false|          0|            false|        ${ADMIN_VER}|     root|jeboehm/mailserve...|                      false|                       1|    false|     0|         3151.0|       0.0|     9463.0|(11,[1,5,7,9],[1....|\n",
      "|                false|              true|           false|          0|            false|          ${BASETAG}|$vnc_user|accetto/ubuntu-vn...|                      false|                       0|    false|     0|         1410.0|     582.0|     2774.0|(11,[1,5,6,7],[1....|\n",
      "|                false|              true|           false|          0|            false|          ${BASETAG}|$vnc_user|accetto/ubuntu-vn...|                      false|                       0|    false|     0|         1410.0|     582.0|     2774.0|(11,[1,5,6,7],[1....|\n",
      "|                false|              true|           false|          0|            false|          ${BASETAG}|     root|         ${BASEREPO}|                      false|                       0|    false|     0|         1410.0|       0.0|     5093.0|(11,[1,5,7],[1.0,...|\n",
      "|                false|              true|           false|          0|            false|     ${BASE_VERSION}|     root|   ${BASE_CONTAINER}|                      false|                       0|    false|     0|         1664.0|       0.0|     5094.0|(11,[1,5,7],[1.0,...|\n",
      "|                false|              true|           false|          0|            false|     ${BASE_VERSION}|     root|hsac/fitnesse-fix...|                      false|                       0|    false|     0|         1664.0|       0.0|     3629.0|(11,[1,5,7],[1.0,...|\n",
      "|                false|              true|           false|          0|            false|     ${CODE_VERSION}|     root|    clipper/lib_base|                      false|                       0|    false|     0|          828.0|       0.0|     3069.0|(11,[1,5,7],[1.0,...|\n",
      "|                false|              true|           false|          0|            false|     ${CODE_VERSION}|     root|    clipper/lib_base|                      false|                       0|    false|     0|          828.0|       0.0|     3069.0|(11,[1,5,7],[1.0,...|\n",
      "+---------------------+------------------+----------------+-----------+-----------------+--------------------+---------+--------------------+---------------------------+------------------------+---------+------+---------------+----------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(training_data, test_data) = feature_vector.randomSplit([0.8, 0.2],seed = 42)\n",
    "training_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/13 19:40:57 WARN DAGScheduler: Broadcasting large task binary with size 1117.3 KiB\n",
      "24/05/13 19:40:58 WARN DAGScheduler: Broadcasting large task binary with size 1118.9 KiB\n",
      "24/05/13 19:40:58 WARN DAGScheduler: Broadcasting large task binary with size 1118.9 KiB\n",
      "24/05/13 19:40:58 WARN DAGScheduler: Broadcasting large task binary with size 1118.9 KiB\n",
      "24/05/13 19:40:58 WARN DAGScheduler: Broadcasting large task binary with size 1118.9 KiB\n",
      "24/05/13 19:40:58 WARN DAGScheduler: Broadcasting large task binary with size 1118.9 KiB\n",
      "24/05/13 19:40:58 WARN DAGScheduler: Broadcasting large task binary with size 1118.9 KiB\n",
      "24/05/13 19:40:58 WARN DAGScheduler: Broadcasting large task binary with size 1118.9 KiB\n",
      "24/05/13 19:40:58 WARN DAGScheduler: Broadcasting large task binary with size 1118.9 KiB\n",
      "24/05/13 19:40:58 WARN DAGScheduler: Broadcasting large task binary with size 1118.9 KiB\n",
      "24/05/13 19:40:58 WARN DAGScheduler: Broadcasting large task binary with size 1118.9 KiB\n",
      "24/05/13 19:40:58 WARN DAGScheduler: Broadcasting large task binary with size 1118.9 KiB\n",
      "24/05/13 19:40:58 WARN DAGScheduler: Broadcasting large task binary with size 1118.9 KiB\n",
      "24/05/13 19:40:58 WARN DAGScheduler: Broadcasting large task binary with size 1118.9 KiB\n",
      "24/05/13 19:40:59 WARN DAGScheduler: Broadcasting large task binary with size 1118.9 KiB\n",
      "24/05/13 19:40:59 WARN DAGScheduler: Broadcasting large task binary with size 1118.9 KiB\n",
      "24/05/13 19:40:59 WARN DAGScheduler: Broadcasting large task binary with size 1118.9 KiB\n",
      "24/05/13 19:40:59 WARN DAGScheduler: Broadcasting large task binary with size 1118.9 KiB\n",
      "24/05/13 19:40:59 WARN DAGScheduler: Broadcasting large task binary with size 1118.9 KiB\n",
      "24/05/13 19:40:59 WARN DAGScheduler: Broadcasting large task binary with size 1118.9 KiB\n",
      "24/05/13 19:40:59 WARN DAGScheduler: Broadcasting large task binary with size 1118.9 KiB\n",
      "24/05/13 19:40:59 WARN DAGScheduler: Broadcasting large task binary with size 1118.9 KiB\n",
      "24/05/13 19:40:59 WARN DAGScheduler: Broadcasting large task binary with size 1118.9 KiB\n",
      "24/05/13 19:40:59 WARN DAGScheduler: Broadcasting large task binary with size 1118.9 KiB\n",
      "24/05/13 19:40:59 WARN DAGScheduler: Broadcasting large task binary with size 1127.6 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------------+\n",
      "|prediction|result|            features|\n",
      "+----------+------+--------------------+\n",
      "|       0.0|     0|(11,[1,5,7,9],[1....|\n",
      "|       0.0|     0|(11,[1,5,6,7],[1....|\n",
      "|       0.0|     0|(11,[1,5,6,7],[1....|\n",
      "|       0.0|     0|(11,[1,5,7],[1.0,...|\n",
      "|       0.0|     0|(11,[1,5,6],[1.0,...|\n",
      "+----------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/13 19:40:59 WARN DAGScheduler: Broadcasting large task binary with size 1139.4 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression [Accuracy] = 0.885815\n",
      "LogisticRegression [Error] = 0.114185 \n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"result\", predictionCol=\"prediction\", metricName=\"accuracy\"\n",
    ")\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(labelCol=\"result\", featuresCol=\"features\")\n",
    "\n",
    "lrModel = lr.fit(training_data)     \n",
    "\n",
    "lr_prediction = lrModel.transform(test_data)\n",
    "lr_prediction.select(\"prediction\", \"result\", \"features\").show(5)\n",
    "\n",
    "lr_accuracy = evaluator.evaluate(lr_prediction)\n",
    "print(\"LogisticRegression [Accuracy] = %g\"% (lr_accuracy))\n",
    "print(\"LogisticRegression [Error] = %g \" % (1.0 - lr_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/13 19:42:20 WARN DAGScheduler: Broadcasting large task binary with size 1112.1 KiB\n",
      "24/05/13 19:42:20 WARN DAGScheduler: Broadcasting large task binary with size 1116.8 KiB\n",
      "24/05/13 19:42:21 WARN DAGScheduler: Broadcasting large task binary with size 1116.8 KiB\n",
      "24/05/13 19:42:21 WARN DAGScheduler: Broadcasting large task binary with size 1122.9 KiB\n",
      "24/05/13 19:42:21 WARN DAGScheduler: Broadcasting large task binary with size 1137.0 KiB\n",
      "24/05/13 19:42:23 WARN DAGScheduler: Broadcasting large task binary with size 1137.8 KiB\n",
      "24/05/13 19:42:24 WARN DAGScheduler: Broadcasting large task binary with size 1138.4 KiB\n",
      "24/05/13 19:42:27 WARN DAGScheduler: Broadcasting large task binary with size 1297.8 KiB\n",
      "24/05/13 19:42:32 WARN DAGScheduler: Broadcasting large task binary with size 1490.6 KiB\n",
      "24/05/13 19:42:41 WARN DAGScheduler: Broadcasting large task binary with size 1370.9 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------------+\n",
      "|prediction|result|            features|\n",
      "+----------+------+--------------------+\n",
      "|       0.0|     0|(11,[1,5,7],[1.0,...|\n",
      "|       0.0|     0|(11,[1,5,7],[1.0,...|\n",
      "|       0.0|     0|(11,[1,5,7],[1.0,...|\n",
      "|       0.0|     0|(11,[1,5,7],[1.0,...|\n",
      "|       0.0|     0|(11,[1,5,7],[1.0,...|\n",
      "+----------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/13 19:42:42 WARN DAGScheduler: Broadcasting large task binary with size 1382.7 KiB\n",
      "[Stage 2105:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier [Accuracy] = 0.943448\n",
      "DecisionTreeClassifier [Error] = 0.0565515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#DecisionTreeClassifier\n",
    "\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "dt_classifier = DecisionTreeClassifier(labelCol=\"result\", featuresCol=\"features\", maxBins=16000)\n",
    "dt_model = dt.fit(training_data)\n",
    "dt_prediction = dt_model.transform(training_data)\n",
    "\n",
    "dt_prediction.select(\"prediction\", \"result\", \"features\").show(5)\n",
    "\n",
    "\n",
    "# Create a MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"result\", predictionCol=\"prediction\")\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = evaluator.evaluate(dt_prediction)\n",
    "\n",
    "# Calculate the error of the model\n",
    "error = 1.0 - accuracy\n",
    "\n",
    "print(\"DecisionTreeClassifier [Accuracy] = %g\" % (accuracy))\n",
    "print(\"DecisionTreeClassifier [Error] = %g\" % (error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/11 10:17:38 WARN DAGScheduler: Broadcasting large task binary with size 1099.9 KiB\n",
      "24/05/11 10:17:38 WARN DAGScheduler: Broadcasting large task binary with size 1104.6 KiB\n",
      "24/05/11 10:17:38 WARN DAGScheduler: Broadcasting large task binary with size 1104.7 KiB\n",
      "24/05/11 10:17:39 WARN DAGScheduler: Broadcasting large task binary with size 1110.7 KiB\n",
      "24/05/11 10:17:39 WARN DAGScheduler: Broadcasting large task binary with size 1126.7 KiB\n",
      "24/05/11 10:17:45 WARN DAGScheduler: Broadcasting large task binary with size 1469.6 KiB\n",
      "24/05/11 10:17:54 WARN DAGScheduler: Broadcasting large task binary with size 1819.9 KiB\n",
      "24/05/11 10:18:10 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "24/05/11 10:18:46 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "24/05/11 10:19:46 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------------+\n",
      "|prediction|result|            features|\n",
      "+----------+------+--------------------+\n",
      "|       1.0|     1|(11,[1,5,7,9],[1....|\n",
      "|       1.0|     1|(11,[1,5,6,7],[1....|\n",
      "|       1.0|     1|(11,[1,5,6,7],[1....|\n",
      "|       1.0|     1|(11,[1,5,7],[1.0,...|\n",
      "|       1.0|     1|(11,[1,5,6],[1.0,...|\n",
      "+----------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/11 10:19:46 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier [Accuracy] = 0.929402\n",
      "RandomForestClassifier [Error] = 0.0705982\n"
     ]
    }
   ],
   "source": [
    "#RandomForestClassifier\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"result\", featuresCol=\"features\", maxBins=16000)\n",
    "rf_model = rf.fit(training_data)\n",
    "rf_prediction = rf_model.transform(test_data)\n",
    "rf_prediction.select(\"prediction\", \"result\", \"features\").show(5)\n",
    "\n",
    "\n",
    "rf_accuracy = evaluator.evaluate(rf_prediction)\n",
    "print(\"RandomForestClassifier [Accuracy] = %g\"% (rf_accuracy))\n",
    "print(\"RandomForestClassifier [Error] = %g\" % (1.0 - rf_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/11 10:22:11 WARN DAGScheduler: Broadcasting large task binary with size 1105.8 KiB\n",
      "24/05/11 10:22:11 WARN DAGScheduler: Broadcasting large task binary with size 1105.8 KiB\n",
      "24/05/11 10:22:12 WARN DAGScheduler: Broadcasting large task binary with size 1111.9 KiB\n",
      "24/05/11 10:22:12 WARN DAGScheduler: Broadcasting large task binary with size 1127.1 KiB\n",
      "24/05/11 10:22:13 WARN DAGScheduler: Broadcasting large task binary with size 1207.4 KiB\n",
      "24/05/11 10:22:14 WARN DAGScheduler: Broadcasting large task binary with size 1208.2 KiB\n",
      "24/05/11 10:22:17 WARN DAGScheduler: Broadcasting large task binary with size 1239.8 KiB\n",
      "24/05/11 10:22:22 WARN DAGScheduler: Broadcasting large task binary with size 1265.7 KiB\n",
      "24/05/11 10:22:33 WARN DAGScheduler: Broadcasting large task binary with size 1365.6 KiB\n",
      "24/05/11 10:22:34 WARN DAGScheduler: Broadcasting large task binary with size 1366.0 KiB\n",
      "24/05/11 10:22:35 WARN DAGScheduler: Broadcasting large task binary with size 1387.8 KiB\n",
      "24/05/11 10:22:38 WARN DAGScheduler: Broadcasting large task binary with size 1526.8 KiB\n",
      "24/05/11 10:22:43 WARN DAGScheduler: Broadcasting large task binary with size 1583.7 KiB\n",
      "24/05/11 10:22:55 WARN DAGScheduler: Broadcasting large task binary with size 1667.1 KiB\n",
      "24/05/11 10:22:55 WARN DAGScheduler: Broadcasting large task binary with size 1667.6 KiB\n",
      "24/05/11 10:22:57 WARN DAGScheduler: Broadcasting large task binary with size 1689.5 KiB\n",
      "24/05/11 10:22:59 WARN DAGScheduler: Broadcasting large task binary with size 1831.8 KiB\n",
      "24/05/11 10:23:05 WARN DAGScheduler: Broadcasting large task binary with size 1885.8 KiB\n",
      "24/05/11 10:23:15 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "24/05/11 10:23:16 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "24/05/11 10:23:18 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "24/05/11 10:23:20 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "24/05/11 10:23:26 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "24/05/11 10:23:36 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "24/05/11 10:23:37 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/05/11 10:23:38 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/05/11 10:23:41 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/05/11 10:23:46 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "24/05/11 10:23:57 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n",
      "24/05/11 10:23:57 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n",
      "24/05/11 10:23:59 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n",
      "24/05/11 10:24:01 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "24/05/11 10:24:07 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "24/05/11 10:24:17 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "24/05/11 10:24:18 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "24/05/11 10:24:19 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "24/05/11 10:24:22 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "24/05/11 10:24:27 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n",
      "24/05/11 10:24:38 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n",
      "24/05/11 10:24:39 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n",
      "24/05/11 10:24:40 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n",
      "24/05/11 10:24:43 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "24/05/11 10:24:48 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "24/05/11 10:24:58 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "24/05/11 10:24:59 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "24/05/11 10:25:00 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "24/05/11 10:25:03 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "24/05/11 10:25:08 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "24/05/11 10:25:19 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/05/11 10:25:20 WARN DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/05/11 10:25:21 WARN DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/05/11 10:25:24 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n",
      "24/05/11 10:25:30 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n",
      "24/05/11 10:25:40 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------------+\n",
      "|prediction|result|            features|\n",
      "+----------+------+--------------------+\n",
      "|       1.0|     1|(11,[1,5,7,9],[1....|\n",
      "|       1.0|     1|(11,[1,5,6,7],[1....|\n",
      "|       1.0|     1|(11,[1,5,6,7],[1....|\n",
      "|       1.0|     1|(11,[1,5,7],[1.0,...|\n",
      "|       1.0|     1|(11,[1,5,6],[1.0,...|\n",
      "+----------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/11 10:25:41 WARN DAGScheduler: Broadcasting large task binary with size 4.6 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient-boosted [Accuracy] = 0.931711\n",
      "Gradient-boosted [Error] = 0.0682893\n"
     ]
    }
   ],
   "source": [
    "#Gradient-boosted tree classifier\n",
    "\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "gbt = GBTClassifier(labelCol=\"result\", featuresCol=\"features\",maxIter=10,maxBins=16000)\n",
    "gbt_model = gbt.fit(training_data)\n",
    "gbt_prediction = gbt_model.transform(test_data)\n",
    "gbt_prediction.select(\"prediction\", \"result\", \"features\").show(5)\n",
    "\n",
    "gbt_accuracy = evaluator.evaluate(gbt_prediction)\n",
    "print(\"Gradient-boosted [Accuracy] = %g\"% (gbt_accuracy))\n",
    "print(\"Gradient-boosted [Error] = %g\"% (1.0 - gbt_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/11 10:27:48 WARN MemoryManager: Total allocation exceeds 95,00% (1 020 054 720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n"
     ]
    }
   ],
   "source": [
    "#Save model\n",
    "\n",
    "dt_model.write().overwrite().save('dt_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/13 19:41:58 WARN DAGScheduler: Broadcasting large task binary with size 1034.3 KiB\n",
      "24/05/13 19:41:58 WARN DAGScheduler: Broadcasting large task binary with size 1034.4 KiB\n",
      "24/05/13 19:41:58 WARN DAGScheduler: Broadcasting large task binary with size 1040.4 KiB\n",
      "24/05/13 19:41:59 WARN DAGScheduler: Broadcasting large task binary with size 1054.9 KiB\n",
      "24/05/13 19:42:00 WARN DAGScheduler: Broadcasting large task binary with size 1055.7 KiB\n",
      "24/05/13 19:42:01 WARN DAGScheduler: Broadcasting large task binary with size 1056.3 KiB\n",
      "24/05/13 19:42:03 WARN DAGScheduler: Broadcasting large task binary with size 1216.3 KiB\n",
      "24/05/13 19:42:06 WARN DAGScheduler: Broadcasting large task binary with size 1430.6 KiB\n",
      "24/05/13 19:42:14 WARN MemoryManager: Total allocation exceeds 95,00% (1 020 054 720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "24/05/13 19:42:15 WARN DAGScheduler: Broadcasting large task binary with size 1344.6 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline model [Accuracy] = 0.929526\n",
      "Pipeline model [Error] = 0.0704736 \n"
     ]
    }
   ],
   "source": [
    "#Pipeline\n",
    "\n",
    "from pyspark.ml.pipeline import PipelineModel\n",
    "\n",
    "df_pipe = spark.read.parquet('../part.0.parquet')\n",
    "\n",
    "train, test = df_pipe.randomSplit([0.8, 0.2])\n",
    "\n",
    "\n",
    "tag_index = StringIndexer(inputCol='image_tag', outputCol=\"image_tag_index\", handleInvalid=\"skip\")\n",
    "user_index = StringIndexer(inputCol='user', outputCol=\"user_index\", handleInvalid=\"skip\")\n",
    "image_index = StringIndexer(inputCol='image', outputCol=\"image_index\", handleInvalid=\"skip\")\n",
    "\n",
    "feature = VectorAssembler(\n",
    "    inputCols=[\"has_install_or_update\", \n",
    "                             \"has_clean_commands\", \n",
    "                             \"has_exposed_port\", \n",
    "                             \"port_number\", \n",
    "                             \"has_setuid_setgid\", \n",
    "                             \"image_tag_index\", \n",
    "                             \"user_index\",\n",
    "                             \"image_index\",\n",
    "                             \"has_package_update_commands\",\n",
    "                             \"dangerous_commands_count\",\n",
    "                             \"safe_copy\"],\n",
    "    outputCol=\"features\")\n",
    "\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier(labelCol=\"result\", featuresCol=\"features\", maxBins=16000)\n",
    "\n",
    "pipeline = Pipeline(stages=[tag_index, user_index, image_index, feature, dt_classifier])\n",
    "\n",
    "p_model = pipeline.fit(train)\n",
    "\n",
    "p_model.write().overwrite().save('p_model')\n",
    "model = PipelineModel.load('p_model')\n",
    "\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"result\", predictionCol=\"prediction\", metricName=\"accuracy\"\n",
    ")\n",
    "\n",
    "prediction = p_model.transform(test)\n",
    "# test.show(10)\n",
    "p_accuracy = evaluator.evaluate(prediction)\n",
    "print(\"Pipeline model [Accuracy] = %g\"% (p_accuracy))\n",
    "print(\"Pipeline model [Error] = %g \" % (1.0 - p_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/13 20:11:47 WARN DAGScheduler: Broadcasting large task binary with size 1098.9 KiB\n",
      "24/05/13 20:11:52 WARN DAGScheduler: Broadcasting large task binary with size 1029.3 KiB\n",
      "24/05/13 20:11:59 WARN DAGScheduler: Broadcasting large task binary with size 1098.9 KiB\n",
      "24/05/13 20:12:04 WARN DAGScheduler: Broadcasting large task binary with size 1029.3 KiB\n",
      "[Stage 3686:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py:853\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 853\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_items\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopleft\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 14\u001b[0m\n\u001b[1;32m      5\u001b[0m paramGrid \u001b[38;5;241m=\u001b[39m ParamGridBuilder() \\\n\u001b[1;32m      6\u001b[0m    \u001b[38;5;241m.\u001b[39maddGrid(dt_classifier\u001b[38;5;241m.\u001b[39mmaxDepth, [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]) \\\n\u001b[1;32m      7\u001b[0m    \u001b[38;5;241m.\u001b[39maddGrid(dt_classifier\u001b[38;5;241m.\u001b[39mminInfoGain, [\u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.15\u001b[39m]) \\\n\u001b[1;32m      8\u001b[0m    \u001b[38;5;241m.\u001b[39mbuild()\n\u001b[1;32m     10\u001b[0m tvs \u001b[38;5;241m=\u001b[39m TrainValidationSplit(estimator\u001b[38;5;241m=\u001b[39mpipeline,\n\u001b[1;32m     11\u001b[0m                             estimatorParamMaps\u001b[38;5;241m=\u001b[39mparamGrid,\n\u001b[1;32m     12\u001b[0m                             evaluator\u001b[38;5;241m=\u001b[39mevaluator,\n\u001b[1;32m     13\u001b[0m                             trainRatio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtvs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m best_model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mbestModel\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest model hyperparameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pyspark/ml/base.py:161\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pyspark/ml/tuning.py:1220\u001b[0m, in \u001b[0;36mTrainValidationSplit._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m   1218\u001b[0m pool \u001b[38;5;241m=\u001b[39m ThreadPool(processes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetParallelism(), numModels))\n\u001b[1;32m   1219\u001b[0m metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m numModels\n\u001b[0;32m-> 1220\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, metric, subModel \u001b[38;5;129;01min\u001b[39;00m pool\u001b[38;5;241m.\u001b[39mimap_unordered(\u001b[38;5;28;01mlambda\u001b[39;00m f: f(), tasks):\n\u001b[1;32m   1221\u001b[0m     metrics[j] \u001b[38;5;241m=\u001b[39m metric\n\u001b[1;32m   1222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m collectSubModelsParam:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py:858\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 858\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    860\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_items\u001b[38;5;241m.\u001b[39mpopleft()\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/13 20:12:10 WARN DAGScheduler: Broadcasting large task binary with size 1098.9 KiB\n",
      "[Stage 3688:>                                                       (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "#Hyperparams\n",
    "\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "   .addGrid(dt_classifier.maxDepth, [2, 3, 4]) \\\n",
    "   .addGrid(dt_classifier.minInfoGain, [0.05, 0.1, 0.15]) \\\n",
    "   .build()\n",
    "print(dt_classifier.maxDepth)\n",
    "tvs = TrainValidationSplit(estimator=pipeline,\n",
    "                            estimatorParamMaps=paramGrid,\n",
    "                            evaluator=evaluator,\n",
    "                            trainRatio=0.8)\n",
    "model = tvs.fit(train)\n",
    "\n",
    "best_model = model.bestModel\n",
    "print(\"Best model hyperparameters:\")\n",
    "print(\"maxDepth:\", best_model.stages[-1].getOrDefault(\"maxDepth\"))\n",
    "print(\"maxBins:\", best_model.stages[-1].getOrDefault(\"maxBins\"))\n",
    "print(\"minInfoGain:\", best_model.stages[-1].getOrDefault(\"minInfoGain\"))\n",
    "\n",
    "prediction = best_model.transform(test)\n",
    "accuracy = evaluator.evaluate(prediction)\n",
    "error = 1.0 - accuracy\n",
    "print(\"Best model accuracy:\", accuracy)\n",
    "print(\"Best model error:\", error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
